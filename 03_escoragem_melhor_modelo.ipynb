{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "import pickle\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from utils import functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./databases/air_system_previous_years.csv').replace(to_replace= 'na', value= np.nan)\n",
    "\n",
    "train_data['class'] = train_data['class'].map({\n",
    "    'neg' : 0,\n",
    "    'pos' : 1\n",
    "})\n",
    "\n",
    "train_data = train_data.astype(dtype= float).copy()\n",
    "\n",
    "train_data['class'] = train_data['class'].astype(dtype= int).copy()\n",
    "\n",
    "y_train = train_data['class']\n",
    "\n",
    "train_data = train_data.drop(columns=['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Isolation Forest - Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./artefatos/IsolationForest/pipeline.pkl', mode= 'rb') as file:\n",
    "    if_pipeline = pickle.load(file)\n",
    "\n",
    "if_pipeline = if_pipeline.fit(train_data)\n",
    "train_data['anomaly_scores'] = if_pipeline.decision_function(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PCA - Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./artefatos/GMM/PCA_pipeline.pkl', mode= 'rb') as file:\n",
    "    pca_pipeline = pickle.load(file)\n",
    "\n",
    "pca_pipeline = pca_pipeline.fit(train_data)\n",
    "train_data_decomp = pd.DataFrame(pca_pipeline.transform(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GMM - Clustering - Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./artefatos/GMM/GMM_model.pkl', mode= 'rb') as file:\n",
    "    gmm_model = pickle.load(file)\n",
    "gmm_model = gmm_model.fit(train_data_decomp)\n",
    "train_data['cluster'] = gmm_model.predict(train_data_decomp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* XGBoost - Classification - Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./artefatos/Boosting/pipeline.pkl', mode= 'rb') as file:\n",
    "    xgbm_pipe = pickle.load(file)\n",
    "\n",
    "with open('./artefatos/Boosting/pipeline_feature_names_out.pkl', mode= 'rb') as file:\n",
    "    xgbm_feature_names = pickle.load(file)\n",
    "\n",
    "with open('./artefatos/XGBM/XGBM_best_config.pkl', mode= 'rb') as file:\n",
    "    xgbm_config = pickle.load(file)\n",
    "\n",
    "train_data = pd.DataFrame(\n",
    "    data = xgbm_pipe.fit_transform(train_data),\n",
    "    columns= xgbm_feature_names\n",
    ")\n",
    "\n",
    "train_data, to_drop = functions.remove_highly_correlated_features(\n",
    "    df= train_data,\n",
    "    threshold= 0.6\n",
    ")\n",
    "\n",
    "var_fs = VarianceThreshold().fit(train_data)\n",
    "\n",
    "to_drop_variance = train_data.loc[:, ~var_fs.get_support()].columns.to_list()\n",
    "\n",
    "train_data = train_data.drop(columns= to_drop_variance)\n",
    "\n",
    "xgbm_model = XGBClassifier(**xgbm_config.params)\n",
    "\n",
    "xgbm_model = xgbm_model.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./databases/air_system_present_year.csv').replace(to_replace= 'na', value= np.nan)\n",
    "\n",
    "test_data['class'] = test_data['class'].map({\n",
    "    'neg' : 0,\n",
    "    'pos' : 1\n",
    "})\n",
    "\n",
    "test_data = test_data.astype(dtype= float).copy()\n",
    "\n",
    "test_data['class'] = test_data['class'].astype(dtype= int).copy()\n",
    "\n",
    "y_test = test_data['class']\n",
    "\n",
    "test_data = test_data.drop(columns=['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Isolation Forest - Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['anomaly_scores'] = if_pipeline.decision_function(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PCA - Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_decomp = pd.DataFrame(pca_pipeline.transform(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM - Clustering - Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['cluster'] = gmm_model.predict(test_data_decomp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* XGBoost - Classification - Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29065"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.DataFrame(\n",
    "    data = xgbm_pipe.transform(test_data),\n",
    "    columns= xgbm_feature_names\n",
    ")\n",
    "\n",
    "test_data = test_data.drop(columns= to_drop)\n",
    "\n",
    "test_data = test_data.drop(columns= to_drop_variance)\n",
    "\n",
    "y_pred = xgbm_model.predict(test_data)\n",
    "\n",
    "functions.loss_function(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
